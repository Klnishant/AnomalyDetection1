{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c4cb76-6bcc-4e9a-97a2-fe954794e107",
   "metadata": {},
   "source": [
    "#### Q1. What is anomaly detection and what is its purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8cd348-edfe-46f1-b980-f419ca7c5af7",
   "metadata": {},
   "source": [
    "Ans--> Anomaly detection, also known as outlier detection, is a technique used to identify unusual or abnormal patterns or instances in a dataset that deviate significantly from the expected or normal behavior. The purpose of anomaly detection is to distinguish rare and anomalous observations from the majority of normal data points.\n",
    "\n",
    "Anomalies can represent various types of unexpected events or patterns, such as fraudulent transactions, network intrusions, manufacturing defects, medical anomalies, or unusual behavior in sensor data. By detecting anomalies, businesses and organizations can gain insights into potential problems, risks, or opportunities that may require further investigation or action.\n",
    "\n",
    "The primary objectives of anomaly detection are:\n",
    "\n",
    "1. Identification of Unusual Patterns: Anomaly detection aims to identify instances that differ significantly from the norm or the expected behavior. It helps uncover patterns that are outside the usual distribution of the data and may provide insights into unknown or unforeseen events.\n",
    "\n",
    "2. Early Warning and Risk Management: By detecting anomalies in real-time or near real-time, anomaly detection can provide early warnings of potential issues or risks. This allows businesses to take proactive measures to mitigate or address the anomalies before they escalate into significant problems.\n",
    "\n",
    "3. Data Quality Assurance: Anomaly detection can be used to identify errors or inconsistencies in data, ensuring data quality and integrity. By identifying outliers or anomalies caused by data entry errors, measurement errors, or data corruption, organizations can maintain the accuracy and reliability of their data.\n",
    "\n",
    "4. Fraud and Intrusion Detection: Anomaly detection is extensively used in various domains to identify fraudulent activities, such as credit card fraud, network intrusions, or cybersecurity threats. By detecting unusual patterns or behaviors, it helps protect systems, assets, and sensitive information.\n",
    "\n",
    "Anomaly detection techniques vary depending on the nature of the data and the specific problem domain. It involves statistical methods, machine learning algorithms, time series analysis, and domain-specific techniques to identify and characterize anomalies. The goal is to provide actionable insights and enable informed decision-making based on the detection of unusual or abnormal patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbedde1d-77bd-4d80-b599-8615dd6d1856",
   "metadata": {},
   "source": [
    "#### Q2. What are the key challenges in anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6562d568-26fc-464f-9c65-637dca6210c9",
   "metadata": {},
   "source": [
    "Ans--> Anomaly detection poses several challenges that need to be addressed to achieve accurate and effective detection. Some of the key challenges in anomaly detection are:\n",
    "\n",
    "1. Lack of Labeled Anomaly Data: Anomaly detection often relies on labeled data for training supervised models. However, obtaining labeled anomaly data can be challenging as anomalies are typically rare and often require expert knowledge or manual identification. This scarcity of labeled data can make it difficult to build robust anomaly detection models.\n",
    "\n",
    "2. Imbalanced Data: Anomalies are often significantly outnumbered by normal data points, resulting in imbalanced datasets. This imbalance can lead to biased models that prioritize accuracy on the majority class, making it challenging to detect rare anomalies effectively.\n",
    "\n",
    "3. Concept Drift: In real-world scenarios, the characteristics and patterns of anomalies may evolve or change over time. This concept drift poses challenges for static anomaly detection models, which may become less effective as the data distribution shifts. Adaptation techniques or continuous monitoring of the data distribution are necessary to handle concept drift.\n",
    "\n",
    "4. High-Dimensional Data: Anomaly detection becomes more challenging as the dimensionality of the data increases. The curse of dimensionality can cause sparsity of data, making it difficult to identify anomalies effectively. Dimensionality reduction techniques or specialized algorithms for high-dimensional data are often required to address this challenge.\n",
    "\n",
    "5. Contextual Understanding: Anomalies are often context-dependent, and their definition may vary across different domains and applications. It is crucial to have a deep understanding of the domain and the specific context to define anomalies accurately. The lack of contextual knowledge can lead to false positives or missed anomalies.\n",
    "\n",
    "6. Noise and Outliers: Distinguishing between anomalies and noisy data or outliers that are not of interest poses a challenge. Outliers can be caused by measurement errors, data preprocessing issues, or natural variations. Differentiating true anomalies from such outliers requires careful analysis and appropriate preprocessing techniques.\n",
    "\n",
    "7. Scalability and Real-Time Processing: Anomaly detection may need to handle large-scale datasets or real-time streaming data. Ensuring scalability and efficiency while maintaining accurate detection becomes a challenge, particularly when dealing with high-speed data streams or distributed systems.\n",
    "\n",
    "Addressing these challenges requires a combination of domain knowledge, appropriate feature engineering, robust modeling techniques, and continuous monitoring and adaptation of the anomaly detection system. It is crucial to select and customize appropriate algorithms and methodologies based on the specific characteristics and requirements of the data and the application domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8e6071-364a-43a6-b480-eb42dc886a8d",
   "metadata": {},
   "source": [
    "#### Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517155f-27c7-49b9-842e-bd5cbc2fb511",
   "metadata": {},
   "source": [
    "Ans--> Unsupervised anomaly detection and supervised anomaly detection differ in their approach to detecting anomalies and the availability of labeled data during the detection process.\n",
    "\n",
    "1. Data Labeling: In unsupervised anomaly detection, labeled anomaly data is not required for training. The algorithm aims to identify anomalies based solely on the characteristics and patterns inherent in the data. On the other hand, supervised anomaly detection requires labeled anomaly data during the training phase. The algorithm learns from both normal and anomaly instances, leveraging the labeled anomalies to build a model that can differentiate between normal and abnormal patterns.\n",
    "\n",
    "2. Training Process: Unsupervised anomaly detection algorithms operate in an unsupervised manner, meaning they do not rely on class labels or prior knowledge of anomalies. They learn patterns from the data itself and identify instances that deviate significantly from the norm. Supervised anomaly detection algorithms, in contrast, require labeled anomalies during the training phase. The model is trained to recognize the specific characteristics of anomalies based on the labeled data.\n",
    "\n",
    "3. Generalizability: Unsupervised anomaly detection techniques aim to detect anomalies in new, unseen data points based on the learned patterns from the training data. They generally have greater generalizability as they are not limited to specific labeled anomaly instances. In supervised anomaly detection, the model is specifically trained on known anomaly instances and may not generalize well to new or different types of anomalies.\n",
    "\n",
    "4. Flexibility: Unsupervised anomaly detection methods are more flexible in handling different types of anomalies since they are not constrained by the specific anomalies labeled during training. They can adapt to unknown or evolving anomalies. Supervised anomaly detection, on the other hand, is limited to the types of anomalies present in the labeled training data.\n",
    "\n",
    "5. Dataset Availability: Unsupervised anomaly detection can be applied when labeled anomaly data is scarce or unavailable. It is suitable for scenarios where anomalies are rare, and labeling them is challenging. Supervised anomaly detection requires a sufficient amount of labeled anomaly data, which may not always be readily available.\n",
    "\n",
    "The choice between unsupervised and supervised anomaly detection depends on the availability of labeled data, the characteristics of anomalies, and the specific requirements of the application. Unsupervised methods are more commonly used when labeled anomaly data is scarce or when there is a need to detect novel or unknown anomalies. Supervised methods are preferred when labeled anomaly data is available and when specific types of anomalies need to be detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4c2ce-6894-44d5-a413-f0845d4763f9",
   "metadata": {},
   "source": [
    "#### Q4. What are the main categories of anomaly detection algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e49dd2a-8d4d-4c83-9113-63d2775ae923",
   "metadata": {},
   "source": [
    "Ans--> Anomaly detection algorithms can be broadly categorized into the following main categories based on their approach and underlying techniques:\n",
    "\n",
    "1. Statistical Methods: Statistical methods assume that normal data follows a known statistical distribution, such as Gaussian (normal) distribution. Anomalies are then identified as data points that deviate significantly from the expected statistical properties, such as mean, variance, or probability density. Common statistical techniques used for anomaly detection include Z-score, Mahalanobis distance, Gaussian mixture models, and the Boxplot method.\n",
    "\n",
    "2. Machine Learning-based Methods: Machine learning algorithms can be employed for anomaly detection by training models to distinguish between normal and abnormal patterns. Supervised learning algorithms, such as Support Vector Machines (SVM) and Random Forests, can be used when labeled anomaly data is available. Unsupervised learning algorithms, including Clustering (e.g., K-means, DBSCAN), Autoencoders, and One-Class SVM, can be used when labeled anomaly data is scarce or unavailable.\n",
    "\n",
    "3. Nearest Neighbor-based Methods: Nearest neighbor methods detect anomalies by measuring the distance or dissimilarity of data points to their nearest neighbors. Anomalies are identified as data points that have significantly different distances compared to their neighbors. Nearest neighbor algorithms used for anomaly detection include k-Nearest Neighbors (k-NN), Local Outlier Factor (LOF), and Isolation Forest.\n",
    "\n",
    "4. Information Theory-based Methods: Information theory-based methods detect anomalies by measuring the amount of information needed to describe or represent the data. Anomalies are identified as data points that require a significantly higher amount of information or have unexpected information content. Examples of information theory-based algorithms include the Minimum Description Length (MDL) principle, Kolmogorov Complexity, and Shannon Entropy.\n",
    "\n",
    "5. Domain-specific Methods: Anomaly detection algorithms can also be tailored to specific domains or applications. These methods leverage domain-specific knowledge, features, or constraints to identify anomalies. For example, in network intrusion detection, methods like Signature-based Detection and Behavior-based Detection are used. In time series data, techniques like Change Point Detection and Seasonal Decomposition of Time Series (STL) can be employed.\n",
    "\n",
    "It's worth noting that these categories are not mutually exclusive, and there can be overlap between different techniques. The choice of an appropriate anomaly detection algorithm depends on the characteristics of the data, the availability of labeled data, the nature of anomalies, and the specific requirements of the application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364f618-0cf9-4798-b350-f950d050a09a",
   "metadata": {},
   "source": [
    "#### Q5. What are the main assumptions made by distance-based anomaly detection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacba3e5-2c17-4f72-bca9-e43d9f2266ad",
   "metadata": {},
   "source": [
    "Ans--> Distance-based anomaly detection methods, such as k-Nearest Neighbors (k-NN) and Local Outlier Factor (LOF), make certain assumptions about the data and the distribution of anomalies. The main assumptions include:\n",
    "\n",
    "1. Density-based Assumption: Distance-based anomaly detection methods assume that normal data instances are surrounded by other normal instances and form dense regions in the feature space. Anomalies, on the other hand, are assumed to be located in sparser regions or isolated from the majority of normal instances. This assumption implies that anomalies have lower local density compared to normal instances.\n",
    "\n",
    "2. Local Neighborhood Assumption: These methods assume that normal instances have a similar density and distribution in their local neighborhoods. In other words, normal instances are expected to have similar characteristics and exhibit consistent patterns within their local proximity. Anomalies, however, are expected to deviate significantly from this normal behavior and have different characteristics compared to their local neighborhood.\n",
    "\n",
    "3. Distance Measure Assumption: Distance-based methods assume that a meaningful distance or dissimilarity measure can be defined between instances in the feature space. The assumption is that the distance between normal instances is relatively small, indicating similarity, while the distance between anomalies and normal instances is larger, indicating dissimilarity.\n",
    "\n",
    "It's important to note that these assumptions may not hold in all cases, and the effectiveness of distance-based anomaly detection methods can be influenced by violations of these assumptions. For example, in high-dimensional data spaces, the curse of dimensionality can lead to challenges in defining meaningful distances or identifying local neighborhoods accurately. Additionally, in certain types of anomalies or complex data distributions, anomalies may not exhibit significantly lower density or clear separation from normal instances, making their detection more challenging.\n",
    "\n",
    "Therefore, it is crucial to consider the characteristics of the data and assess the suitability of the assumptions made by distance-based methods for a given anomaly detection task. It is recommended to compare and combine multiple techniques and consider domain knowledge to ensure robust and accurate detection of anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab8828-ea2b-434c-ac3c-ca50cb2c5fc4",
   "metadata": {},
   "source": [
    "#### Q6. How does the LOF algorithm compute anomaly scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e472a97c-2c7a-4ab2-96d5-4d5a92ca6d21",
   "metadata": {},
   "source": [
    "Ans--> The Local Outlier Factor (LOF) algorithm computes anomaly scores for each data point in a dataset based on its local density compared to the local densities of its neighbors. The anomaly score reflects the degree of outlierness or abnormality of each data point. The steps involved in computing the anomaly scores using the LOF algorithm are as follows:\n",
    "\n",
    "1. Nearest Neighbors: For each data point, the algorithm identifies its k nearest neighbors based on a chosen distance metric (e.g., Euclidean distance).\n",
    "\n",
    "2. Reachability Distance: The reachability distance of a data point A from another data point B is the maximum of two values: the distance between A and B and the reachability distance of B. In other words, it measures the distance or dissimilarity required to reach data point A from data point B.\n",
    "\n",
    "3. Local Reachability Density: The local reachability density of a data point A is the inverse of the average reachability distance of its k nearest neighbors. It represents the inverse of the average density of the local neighborhood of A.\n",
    "\n",
    "4. Local Outlier Factor (LOF): The LOF of a data point A is calculated by comparing its local reachability density with the local reachability densities of its k nearest neighbors. Specifically, the LOF of A is the average ratio of the local reachability densities of its k nearest neighbors to its own local reachability density. A higher LOF value indicates that A has a lower local density compared to its neighbors and is more likely to be an outlier or anomaly.\n",
    "\n",
    "5. Anomaly Score: The anomaly score of a data point is computed based on its LOF value. The LOF values are normalized to have a range between 0 and 1, where 1 represents the highest outlierness or abnormality.\n",
    "\n",
    "The LOF algorithm assigns higher anomaly scores to data points with LOF values significantly greater than 1, indicating that they have a lower local density compared to their neighbors. Data points with anomaly scores closer to 0 are considered more normal or similar to their neighbors.\n",
    "\n",
    "By examining the anomaly scores, analysts can identify data points with higher scores as potential anomalies or outliers in the dataset. The LOF algorithm is effective in detecting anomalies in datasets where the anomalies have different local densities compared to the majority of normal instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66023587-e2ab-4702-b335-48ade0a12407",
   "metadata": {},
   "source": [
    "#### Q7. What are the key parameters of the Isolation Forest algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6935e-13ca-40b9-8659-047402aa1b6e",
   "metadata": {},
   "source": [
    "Ans--> The Isolation Forest algorithm, which is an ensemble-based anomaly detection method, has several key parameters that influence its performance and behavior. The main parameters of the Isolation Forest algorithm are:\n",
    "\n",
    "1. Number of Trees (n_estimators): This parameter determines the number of isolation trees to be created in the ensemble. Increasing the number of trees generally improves the performance of the algorithm but also increases the computational complexity. A common rule of thumb is to set a higher number of trees for larger datasets.\n",
    "\n",
    "2. Subsample Size (max_samples): The subsample size determines the number of data points randomly selected to construct each isolation tree. Smaller values of max_samples lead to shorter trees and faster computation, but they can also result in a higher chance of overfitting. It is usually set as a fraction of the total number of data points.\n",
    "\n",
    "3. Maximum Tree Depth (max_depth): The maximum tree depth determines the maximum number of splits that can be made in an isolation tree. Setting a higher value for max_depth can result in more detailed partitions of the data but may also increase the risk of overfitting. It is typically set to a small value such as log2(n), where n is the number of data points.\n",
    "\n",
    "These parameters influence the behavior and performance of the Isolation Forest algorithm. Adjusting these parameters should be done based on the characteristics of the dataset and the desired trade-off between computation time and detection accuracy. Additionally, cross-validation or other model selection techniques can be used to find the optimal values for these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c21c27-8c10-4018-b4eb-d16d20717aad",
   "metadata": {},
   "source": [
    "#### Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e68aa-07fc-4eb5-98c6-737984664b2f",
   "metadata": {},
   "source": [
    "Ans--> To calculate the anomaly score of a data point using k-Nearest Neighbors (KNN) with K=10, we need to consider the ratio of the average distance to the 10th nearest neighbor and the distance to the 2nd nearest neighbor for that data point. \n",
    "\n",
    "However, in the given scenario, if a data point has only 2 neighbors of the same class within a radius of 0.5, it implies that it does not have 10 neighbors within the specified range. In this case, the anomaly score using KNN with K=10 cannot be accurately determined because there are not enough neighbors to consider.\n",
    "\n",
    "The KNN algorithm requires a sufficient number of neighbors to estimate the local density and assess the outlierness of a data point. If there are only 2 neighbors of the same class within a radius of 0.5, it suggests a limited neighborhood and may not provide enough information to compute a reliable anomaly score using KNN with K=10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba8116-9a3c-4ba0-963b-b934a48b5b7f",
   "metadata": {},
   "source": [
    "#### Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1982e2-795f-4258-b128-612603ecbee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9343c317-b9a7-4088-aee4-814ef194f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd1b2860-14c6-4ab9-8857-09fe999cbcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e42b33b3-7a25-4b91-a520-4b4d8476df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "isolation_forest=IsolationForest(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f87f5db0-f038-471e-9f85-7822c6e2250f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IsolationForest()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IsolationForest</label><div class=\"sk-toggleable__content\"><pre>IsolationForest()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IsolationForest()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isolation_forest.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9eaf0c06-c47e-40e1-b605-a15cac331adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_point=[range(1,15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df39404f-ac3d-446f-9fde-6235d1340688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "anomaly_score = isolation_forest.score_samples(data_point)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fad4b59-278b-4d12-9297-1e268a6eacd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "avg_path_length = isolation_forest.decision_function(data_point)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebb918d6-6c73-4f36-a243-c4a81fc12942",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_score = 1 - (avg_path_length / isolation_forest.offset_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2073437d-e826-4bcd-860b-699befba8248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Score: 0.5569600871624294\n"
     ]
    }
   ],
   "source": [
    "print(\"Anomaly Score:\", anomaly_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03db8e2-67d7-40f3-96af-150b7ae77fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
